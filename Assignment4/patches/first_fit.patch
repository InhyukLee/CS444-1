diff -ur linux-yocto-3.14/arch/x86/syscalls/syscall_32.tbl linux-yocto-3.14-FF/arch/x86/syscalls/syscall_32.tbl
--- linux-yocto-3.14/arch/x86/syscalls/syscall_32.tbl	2017-06-04 21:14:02.336507847 -0700
+++ linux-yocto-3.14-FF/arch/x86/syscalls/syscall_32.tbl	2017-05-30 18:54:40.652762000 -0700
@@ -359,3 +359,6 @@
 350	i386	finit_module		sys_finit_module
 351	i386	sched_setattr		sys_sched_setattr
 352	i386	sched_getattr		sys_sched_getattr
+
+353 i386    free_slob_space     sys_free_slob_space
+354 i386    total_slob_space    sys_total_slob_space
\ No newline at end of file
diff -ur linux-yocto-3.14/include/linux/syscalls.h linux-yocto-3.14-FF/include/linux/syscalls.h
--- linux-yocto-3.14/include/linux/syscalls.h	2017-06-04 21:14:04.196514864 -0700
+++ linux-yocto-3.14-FF/include/linux/syscalls.h	2017-05-30 18:54:40.652762000 -0700
@@ -855,4 +855,7 @@
 asmlinkage long sys_kcmp(pid_t pid1, pid_t pid2, int type,
 			 unsigned long idx1, unsigned long idx2);
 asmlinkage long sys_finit_module(int fd, const char __user *uargs, int flags);
+
+asmlinkage long sys_free_slob_space(void);
+asmlinkage long sys_total_slob_space(void);
 #endif
diff -ur linux-yocto-3.14/mm/slob.c linux-yocto-3.14-FF/mm/slob.c
--- linux-yocto-3.14/mm/slob.c	2017-06-04 21:14:04.332515457 -0700
+++ linux-yocto-3.14-FF/mm/slob.c	2017-05-30 18:54:40.656762000 -0700
@@ -280,6 +280,8 @@
 	else
 		slob_list = &free_slob_large;
 
+	
+
 	spin_lock_irqsave(&slob_lock, flags);
 	/* Iterate through each partially free page, try to find room */
 	list_for_each_entry(sp, slob_list, list) {
@@ -643,3 +645,75 @@
 {
 	slab_state = FULL;
 }
+
+/**
+ * sys_free_slob_space / sys_total_slob_space ~= 0
+ */
+
+/* funtionality copied from slob alloc */
+asmlinkage long sys_total_slob_space(void){
+	long num_pages = 0; /*total pages in all lists */
+	struct list_head *slob_list; /* head temp */
+	struct page *sp;
+	unsigned long flags;
+
+	printk("slob: running sys_total_slob_space\n");
+
+	spin_lock_irqsave(&slob_lock, flags);
+
+	/* small */
+	slob_list = &free_slob_small;
+	list_for_each_entry(sp, slob_list, list) {
+		num_pages++;
+	}
+
+	/* medium */
+	slob_list = &free_slob_medium;
+	list_for_each_entry(sp, slob_list, list) {
+		num_pages++;
+	}
+
+	/* large */
+	slob_list = &free_slob_large;
+	list_for_each_entry(sp, slob_list, list) {
+		num_pages++;
+	}
+
+	spin_unlock_irqrestore(&slob_lock, flags);
+
+	return num_pages * SLOB_UNITS(PAGE_SIZE);
+}
+
+/* funtionality copied from slob alloc */
+asmlinkage long sys_free_slob_space(void){
+	long free_space = 0; /* total unused space in all pages */
+	struct list_head *slob_list; /* head temp */
+	struct page *sp;
+	unsigned long flags;
+
+	printk("slob: running sys_free_slob_space\n");
+
+	spin_lock_irqsave(&slob_lock, flags);
+
+	/* small */
+	slob_list = &free_slob_small;
+	list_for_each_entry(sp, slob_list, list) {
+		free_space += sp->units;
+	}
+
+	/* medium */
+	slob_list = &free_slob_medium;
+	list_for_each_entry(sp, slob_list, list) {
+		free_space += sp->units;
+	}
+
+	/* large */
+	slob_list = &free_slob_large;
+	list_for_each_entry(sp, slob_list, list) {
+		free_space += sp->units;
+	}
+
+	spin_unlock_irqrestore(&slob_lock, flags);
+
+	return free_space;
+}
